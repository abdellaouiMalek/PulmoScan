{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D DenseNet for Cancer Stage Classification\n",
    "\n",
    "This notebook implements a 3D DenseNet model for cancer stage classification from CT scans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "# Import the DenseNet model\n",
    "from densenet_3d import DenseNet121_3D, DenseNet169_3D, DenseNet201_3D\n",
    "\n",
    "# Import the dataset\n",
    "from direct_dataset import DirectCTScanDataset\n",
    "\n",
    "# Import custom loss functions\n",
    "from focal_loss import FocalLoss, CombinedLoss\n",
    "\n",
    "# Import training functions\n",
    "from train_3d_densenet import train_model, evaluate_model, plot_training_history, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "csv_path = \"E:/cancer stage/lung_csv.csv\"  # CSV file with patient IDs and cancer stage labels\n",
    "patch_size = (64, 64, 64)  # Size of patches to extract from CT volumes\n",
    "batch_size = 8  # Batch size for training\n",
    "num_epochs = 30  # Maximum number of epochs (increased for better convergence)\n",
    "patience = 15  # Patience for early stopping (increased to allow more exploration)\n",
    "learning_rate = 0.0005  # Initial learning rate (reduced for more stable training)\n",
    "weight_decay = 5e-4  # Weight decay for regularization (increased for better regularization)\n",
    "model_save_path = \"densenet121_3d_cancer_stage.pth\"  # Path to save the trained model\n",
    "base_dir = \"E:/cancer stage/NSCLC-Radiomics\"  # Base directory containing patient data\n",
    "target_spacing = (1.0, 1.0, 1.0)  # Target voxel spacing in mm\n",
    "target_shape = (128, 256, 256)  # Target shape for preprocessing\n",
    "use_augmentation = True  # Whether to use augmentation for training\n",
    "model_type = \"densenet121\"  # Model type: densenet121, densenet169, densenet201\n",
    "scheduler_type = \"cosine\"  # Scheduler type: plateau, cosine\n",
    "progressive_unfreezing = True  # Whether to use progressive unfreezing (enabled for better transfer learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets and DataLoaders\n",
    "\n",
    "We'll create datasets that load and preprocess CT scans on-the-fly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets with direct processing...\n",
      "Unique values in Overall.Stage: ['IIIb' 'I' 'II' 'IIIa' nan]\n",
      "Dropping 1 rows with NaN values in Overall.Stage\n",
      "No CT scan directory found for patient LUNG1-001\n",
      "No CT scan directory found for patient LUNG1-004\n",
      "No study directory found for patient LUNG1-007\n",
      "No study directory found for patient LUNG1-036\n",
      "No study directory found for patient LUNG1-050\n",
      "No CT scan directory found for patient LUNG1-051\n",
      "No study directory found for patient LUNG1-058\n",
      "No CT scan directory found for patient LUNG1-065\n",
      "No study directory found for patient LUNG1-067\n",
      "No CT scan directory found for patient LUNG1-077\n",
      "No CT scan directory found for patient LUNG1-082\n",
      "No CT scan directory found for patient LUNG1-083\n",
      "No CT scan directory found for patient LUNG1-086\n",
      "No CT scan directory found for patient LUNG1-093\n",
      "No CT scan directory found for patient LUNG1-094\n",
      "No CT scan directory found for patient LUNG1-096\n",
      "No CT scan directory found for patient LUNG1-097\n",
      "No CT scan directory found for patient LUNG1-099\n",
      "No CT scan directory found for patient LUNG1-103\n",
      "No CT scan directory found for patient LUNG1-105\n",
      "No CT scan directory found for patient LUNG1-106\n",
      "No CT scan directory found for patient LUNG1-109\n",
      "No CT scan directory found for patient LUNG1-113\n",
      "No CT scan directory found for patient LUNG1-116\n",
      "No CT scan directory found for patient LUNG1-118\n",
      "No CT scan directory found for patient LUNG1-120\n",
      "No CT scan directory found for patient LUNG1-121\n",
      "No study directory found for patient LUNG1-128\n",
      "No CT scan directory found for patient LUNG1-129\n",
      "No CT scan directory found for patient LUNG1-130\n",
      "No CT scan directory found for patient LUNG1-134\n",
      "No study directory found for patient LUNG1-135\n",
      "No CT scan directory found for patient LUNG1-137\n",
      "No CT scan directory found for patient LUNG1-139\n",
      "No CT scan directory found for patient LUNG1-144\n",
      "No CT scan directory found for patient LUNG1-146\n",
      "No CT scan directory found for patient LUNG1-148\n",
      "No CT scan directory found for patient LUNG1-151\n",
      "No CT scan directory found for patient LUNG1-152\n",
      "No CT scan directory found for patient LUNG1-153\n",
      "No CT scan directory found for patient LUNG1-167\n",
      "No CT scan directory found for patient LUNG1-172\n",
      "No CT scan directory found for patient LUNG1-183\n",
      "No CT scan directory found for patient LUNG1-191\n",
      "No CT scan directory found for patient LUNG1-193\n",
      "No CT scan directory found for patient LUNG1-197\n",
      "No CT scan directory found for patient LUNG1-199\n",
      "No study directory found for patient LUNG1-200\n",
      "No study directory found for patient LUNG1-202\n",
      "No CT scan directory found for patient LUNG1-205\n",
      "No CT scan directory found for patient LUNG1-208\n",
      "No CT scan directory found for patient LUNG1-211\n",
      "No CT scan directory found for patient LUNG1-212\n",
      "No CT scan directory found for patient LUNG1-214\n",
      "No CT scan directory found for patient LUNG1-217\n",
      "No CT scan directory found for patient LUNG1-222\n",
      "No CT scan directory found for patient LUNG1-223\n",
      "No CT scan directory found for patient LUNG1-226\n",
      "No CT scan directory found for patient LUNG1-229\n",
      "No study directory found for patient LUNG1-230\n",
      "No CT scan directory found for patient LUNG1-234\n",
      "No CT scan directory found for patient LUNG1-235\n",
      "No CT scan directory found for patient LUNG1-237\n",
      "No study directory found for patient LUNG1-238\n",
      "No CT scan directory found for patient LUNG1-240\n",
      "No CT scan directory found for patient LUNG1-241\n",
      "No CT scan directory found for patient LUNG1-243\n",
      "No study directory found for patient LUNG1-250\n",
      "No study directory found for patient LUNG1-251\n",
      "No CT scan directory found for patient LUNG1-252\n",
      "No study directory found for patient LUNG1-254\n",
      "No CT scan directory found for patient LUNG1-256\n",
      "No CT scan directory found for patient LUNG1-264\n",
      "No study directory found for patient LUNG1-265\n",
      "No CT scan directory found for patient LUNG1-267\n",
      "No CT scan directory found for patient LUNG1-272\n",
      "No CT scan directory found for patient LUNG1-276\n",
      "No CT scan directory found for patient LUNG1-278\n",
      "No study directory found for patient LUNG1-279\n",
      "No CT scan directory found for patient LUNG1-281\n",
      "No CT scan directory found for patient LUNG1-285\n",
      "No CT scan directory found for patient LUNG1-286\n",
      "No CT scan directory found for patient LUNG1-298\n",
      "No CT scan directory found for patient LUNG1-299\n",
      "No study directory found for patient LUNG1-301\n",
      "No study directory found for patient LUNG1-302\n",
      "No study directory found for patient LUNG1-312\n",
      "No study directory found for patient LUNG1-314\n",
      "No study directory found for patient LUNG1-316\n",
      "No study directory found for patient LUNG1-319\n",
      "No CT scan directory found for patient LUNG1-321\n",
      "No study directory found for patient LUNG1-322\n",
      "No study directory found for patient LUNG1-324\n",
      "No study directory found for patient LUNG1-325\n",
      "No CT scan directory found for patient LUNG1-326\n",
      "No study directory found for patient LUNG1-327\n",
      "No study directory found for patient LUNG1-329\n",
      "No study directory found for patient LUNG1-330\n",
      "No study directory found for patient LUNG1-333\n",
      "No CT scan directory found for patient LUNG1-335\n",
      "No study directory found for patient LUNG1-336\n",
      "No study directory found for patient LUNG1-338\n",
      "No CT scan directory found for patient LUNG1-341\n",
      "No study directory found for patient LUNG1-344\n",
      "No study directory found for patient LUNG1-346\n",
      "No study directory found for patient LUNG1-348\n",
      "No CT scan directory found for patient LUNG1-349\n",
      "No study directory found for patient LUNG1-351\n",
      "No study directory found for patient LUNG1-352\n",
      "No study directory found for patient LUNG1-354\n",
      "No study directory found for patient LUNG1-355\n",
      "No study directory found for patient LUNG1-356\n",
      "No study directory found for patient LUNG1-357\n",
      "No study directory found for patient LUNG1-358\n",
      "No study directory found for patient LUNG1-359\n",
      "No study directory found for patient LUNG1-360\n",
      "No study directory found for patient LUNG1-361\n",
      "No study directory found for patient LUNG1-362\n",
      "No study directory found for patient LUNG1-363\n",
      "No study directory found for patient LUNG1-364\n",
      "No study directory found for patient LUNG1-365\n",
      "No study directory found for patient LUNG1-366\n",
      "No study directory found for patient LUNG1-367\n",
      "No study directory found for patient LUNG1-368\n",
      "No study directory found for patient LUNG1-369\n",
      "No study directory found for patient LUNG1-370\n",
      "No study directory found for patient LUNG1-371\n",
      "No study directory found for patient LUNG1-373\n",
      "No study directory found for patient LUNG1-374\n",
      "No study directory found for patient LUNG1-375\n",
      "No study directory found for patient LUNG1-376\n",
      "No study directory found for patient LUNG1-377\n",
      "No study directory found for patient LUNG1-378\n",
      "No study directory found for patient LUNG1-379\n",
      "No study directory found for patient LUNG1-380\n",
      "No study directory found for patient LUNG1-381\n",
      "No study directory found for patient LUNG1-382\n",
      "No study directory found for patient LUNG1-383\n",
      "No study directory found for patient LUNG1-384\n",
      "No study directory found for patient LUNG1-385\n",
      "No study directory found for patient LUNG1-386\n",
      "No study directory found for patient LUNG1-387\n",
      "No study directory found for patient LUNG1-388\n",
      "No study directory found for patient LUNG1-389\n",
      "No study directory found for patient LUNG1-390\n",
      "No study directory found for patient LUNG1-391\n",
      "No study directory found for patient LUNG1-392\n",
      "No study directory found for patient LUNG1-393\n",
      "No study directory found for patient LUNG1-394\n",
      "No study directory found for patient LUNG1-395\n",
      "No study directory found for patient LUNG1-396\n",
      "No study directory found for patient LUNG1-397\n",
      "No study directory found for patient LUNG1-398\n",
      "No study directory found for patient LUNG1-399\n",
      "No study directory found for patient LUNG1-400\n",
      "No study directory found for patient LUNG1-401\n",
      "No study directory found for patient LUNG1-402\n",
      "No study directory found for patient LUNG1-403\n",
      "No study directory found for patient LUNG1-404\n",
      "No study directory found for patient LUNG1-405\n",
      "No study directory found for patient LUNG1-406\n",
      "No study directory found for patient LUNG1-407\n",
      "No study directory found for patient LUNG1-408\n",
      "No study directory found for patient LUNG1-409\n",
      "No study directory found for patient LUNG1-410\n",
      "No study directory found for patient LUNG1-411\n",
      "No study directory found for patient LUNG1-412\n",
      "No study directory found for patient LUNG1-413\n",
      "No study directory found for patient LUNG1-414\n",
      "No study directory found for patient LUNG1-415\n",
      "No study directory found for patient LUNG1-416\n",
      "No study directory found for patient LUNG1-417\n",
      "No study directory found for patient LUNG1-418\n",
      "No study directory found for patient LUNG1-419\n",
      "No study directory found for patient LUNG1-420\n",
      "No study directory found for patient LUNG1-421\n",
      "No study directory found for patient LUNG1-422\n",
      "No CT scan directory found for patient LUNG1-029\n",
      "Created train dataset with 170 patients\n",
      "Class weights: tensor([0.1318, 0.5630, 0.0553, 0.2500])\n",
      "Unique values in Overall.Stage: ['IIIb' 'I' 'II' 'IIIa' nan]\n",
      "Dropping 1 rows with NaN values in Overall.Stage\n",
      "No CT scan directory found for patient LUNG1-001\n",
      "No CT scan directory found for patient LUNG1-004\n",
      "No study directory found for patient LUNG1-007\n",
      "No study directory found for patient LUNG1-036\n",
      "No study directory found for patient LUNG1-050\n",
      "No CT scan directory found for patient LUNG1-051\n",
      "No study directory found for patient LUNG1-058\n",
      "No CT scan directory found for patient LUNG1-065\n",
      "No study directory found for patient LUNG1-067\n",
      "No CT scan directory found for patient LUNG1-077\n",
      "No CT scan directory found for patient LUNG1-082\n",
      "No CT scan directory found for patient LUNG1-083\n",
      "No CT scan directory found for patient LUNG1-086\n",
      "No CT scan directory found for patient LUNG1-093\n",
      "No CT scan directory found for patient LUNG1-094\n",
      "No CT scan directory found for patient LUNG1-096\n",
      "No CT scan directory found for patient LUNG1-097\n",
      "No CT scan directory found for patient LUNG1-099\n",
      "No CT scan directory found for patient LUNG1-103\n",
      "No CT scan directory found for patient LUNG1-105\n",
      "No CT scan directory found for patient LUNG1-106\n",
      "No CT scan directory found for patient LUNG1-109\n",
      "No CT scan directory found for patient LUNG1-113\n",
      "No CT scan directory found for patient LUNG1-116\n",
      "No CT scan directory found for patient LUNG1-118\n",
      "No CT scan directory found for patient LUNG1-120\n",
      "No CT scan directory found for patient LUNG1-121\n",
      "No study directory found for patient LUNG1-128\n",
      "No CT scan directory found for patient LUNG1-129\n",
      "No CT scan directory found for patient LUNG1-130\n",
      "No CT scan directory found for patient LUNG1-134\n",
      "No study directory found for patient LUNG1-135\n",
      "No CT scan directory found for patient LUNG1-137\n",
      "No CT scan directory found for patient LUNG1-139\n",
      "No CT scan directory found for patient LUNG1-144\n",
      "No CT scan directory found for patient LUNG1-146\n",
      "No CT scan directory found for patient LUNG1-148\n",
      "No CT scan directory found for patient LUNG1-151\n",
      "No CT scan directory found for patient LUNG1-152\n",
      "No CT scan directory found for patient LUNG1-153\n",
      "No CT scan directory found for patient LUNG1-167\n",
      "No CT scan directory found for patient LUNG1-172\n",
      "No CT scan directory found for patient LUNG1-183\n",
      "No CT scan directory found for patient LUNG1-191\n",
      "No CT scan directory found for patient LUNG1-193\n",
      "No CT scan directory found for patient LUNG1-197\n",
      "No CT scan directory found for patient LUNG1-199\n",
      "No study directory found for patient LUNG1-200\n",
      "No study directory found for patient LUNG1-202\n",
      "No CT scan directory found for patient LUNG1-205\n",
      "No CT scan directory found for patient LUNG1-208\n",
      "No CT scan directory found for patient LUNG1-211\n",
      "No CT scan directory found for patient LUNG1-212\n",
      "No CT scan directory found for patient LUNG1-214\n",
      "No CT scan directory found for patient LUNG1-217\n",
      "No CT scan directory found for patient LUNG1-222\n",
      "No CT scan directory found for patient LUNG1-223\n",
      "No CT scan directory found for patient LUNG1-226\n",
      "No CT scan directory found for patient LUNG1-229\n",
      "No study directory found for patient LUNG1-230\n",
      "No CT scan directory found for patient LUNG1-234\n",
      "No CT scan directory found for patient LUNG1-235\n",
      "No CT scan directory found for patient LUNG1-237\n",
      "No study directory found for patient LUNG1-238\n",
      "No CT scan directory found for patient LUNG1-240\n",
      "No CT scan directory found for patient LUNG1-241\n",
      "No CT scan directory found for patient LUNG1-243\n",
      "No study directory found for patient LUNG1-250\n",
      "No study directory found for patient LUNG1-251\n",
      "No CT scan directory found for patient LUNG1-252\n",
      "No study directory found for patient LUNG1-254\n",
      "No CT scan directory found for patient LUNG1-256\n",
      "No CT scan directory found for patient LUNG1-264\n",
      "No study directory found for patient LUNG1-265\n",
      "No CT scan directory found for patient LUNG1-267\n",
      "No CT scan directory found for patient LUNG1-272\n",
      "No CT scan directory found for patient LUNG1-276\n",
      "No CT scan directory found for patient LUNG1-278\n",
      "No study directory found for patient LUNG1-279\n",
      "No CT scan directory found for patient LUNG1-281\n",
      "No CT scan directory found for patient LUNG1-285\n",
      "No CT scan directory found for patient LUNG1-286\n",
      "No CT scan directory found for patient LUNG1-298\n",
      "No CT scan directory found for patient LUNG1-299\n",
      "No study directory found for patient LUNG1-301\n",
      "No study directory found for patient LUNG1-302\n",
      "No study directory found for patient LUNG1-312\n",
      "No study directory found for patient LUNG1-314\n",
      "No study directory found for patient LUNG1-316\n",
      "No study directory found for patient LUNG1-319\n",
      "No CT scan directory found for patient LUNG1-321\n",
      "No study directory found for patient LUNG1-322\n",
      "No study directory found for patient LUNG1-324\n",
      "No study directory found for patient LUNG1-325\n",
      "No CT scan directory found for patient LUNG1-326\n",
      "No study directory found for patient LUNG1-327\n",
      "No study directory found for patient LUNG1-329\n",
      "No study directory found for patient LUNG1-330\n",
      "No study directory found for patient LUNG1-333\n",
      "No CT scan directory found for patient LUNG1-335\n",
      "No study directory found for patient LUNG1-336\n",
      "No study directory found for patient LUNG1-338\n",
      "No CT scan directory found for patient LUNG1-341\n",
      "No study directory found for patient LUNG1-344\n",
      "No study directory found for patient LUNG1-346\n",
      "No study directory found for patient LUNG1-348\n",
      "No CT scan directory found for patient LUNG1-349\n",
      "No study directory found for patient LUNG1-351\n",
      "No study directory found for patient LUNG1-352\n",
      "No study directory found for patient LUNG1-354\n",
      "No study directory found for patient LUNG1-355\n",
      "No study directory found for patient LUNG1-356\n",
      "No study directory found for patient LUNG1-357\n",
      "No study directory found for patient LUNG1-358\n",
      "No study directory found for patient LUNG1-359\n",
      "No study directory found for patient LUNG1-360\n",
      "No study directory found for patient LUNG1-361\n",
      "No study directory found for patient LUNG1-362\n",
      "No study directory found for patient LUNG1-363\n",
      "No study directory found for patient LUNG1-364\n",
      "No study directory found for patient LUNG1-365\n",
      "No study directory found for patient LUNG1-366\n",
      "No study directory found for patient LUNG1-367\n",
      "No study directory found for patient LUNG1-368\n",
      "No study directory found for patient LUNG1-369\n",
      "No study directory found for patient LUNG1-370\n",
      "No study directory found for patient LUNG1-371\n",
      "No study directory found for patient LUNG1-373\n",
      "No study directory found for patient LUNG1-374\n",
      "No study directory found for patient LUNG1-375\n",
      "No study directory found for patient LUNG1-376\n",
      "No study directory found for patient LUNG1-377\n",
      "No study directory found for patient LUNG1-378\n",
      "No study directory found for patient LUNG1-379\n",
      "No study directory found for patient LUNG1-380\n",
      "No study directory found for patient LUNG1-381\n",
      "No study directory found for patient LUNG1-382\n",
      "No study directory found for patient LUNG1-383\n",
      "No study directory found for patient LUNG1-384\n",
      "No study directory found for patient LUNG1-385\n",
      "No study directory found for patient LUNG1-386\n",
      "No study directory found for patient LUNG1-387\n",
      "No study directory found for patient LUNG1-388\n",
      "No study directory found for patient LUNG1-389\n",
      "No study directory found for patient LUNG1-390\n",
      "No study directory found for patient LUNG1-391\n",
      "No study directory found for patient LUNG1-392\n",
      "No study directory found for patient LUNG1-393\n",
      "No study directory found for patient LUNG1-394\n",
      "No study directory found for patient LUNG1-395\n",
      "No study directory found for patient LUNG1-396\n",
      "No study directory found for patient LUNG1-397\n",
      "No study directory found for patient LUNG1-398\n",
      "No study directory found for patient LUNG1-399\n",
      "No study directory found for patient LUNG1-400\n",
      "No study directory found for patient LUNG1-401\n",
      "No study directory found for patient LUNG1-402\n",
      "No study directory found for patient LUNG1-403\n",
      "No study directory found for patient LUNG1-404\n",
      "No study directory found for patient LUNG1-405\n",
      "No study directory found for patient LUNG1-406\n",
      "No study directory found for patient LUNG1-407\n",
      "No study directory found for patient LUNG1-408\n",
      "No study directory found for patient LUNG1-409\n",
      "No study directory found for patient LUNG1-410\n",
      "No study directory found for patient LUNG1-411\n",
      "No study directory found for patient LUNG1-412\n",
      "No study directory found for patient LUNG1-413\n",
      "No study directory found for patient LUNG1-414\n",
      "No study directory found for patient LUNG1-415\n",
      "No study directory found for patient LUNG1-416\n",
      "No study directory found for patient LUNG1-417\n",
      "No study directory found for patient LUNG1-418\n",
      "No study directory found for patient LUNG1-419\n",
      "No study directory found for patient LUNG1-420\n",
      "No study directory found for patient LUNG1-421\n",
      "No study directory found for patient LUNG1-422\n",
      "No CT scan directory found for patient LUNG1-029\n",
      "Created val dataset with 25 patients\n",
      "Unique values in Overall.Stage: ['IIIb' 'I' 'II' 'IIIa' nan]\n",
      "Dropping 1 rows with NaN values in Overall.Stage\n",
      "No CT scan directory found for patient LUNG1-001\n",
      "No CT scan directory found for patient LUNG1-004\n",
      "No study directory found for patient LUNG1-007\n",
      "No study directory found for patient LUNG1-036\n",
      "No study directory found for patient LUNG1-050\n",
      "No CT scan directory found for patient LUNG1-051\n",
      "No study directory found for patient LUNG1-058\n",
      "No CT scan directory found for patient LUNG1-065\n",
      "No study directory found for patient LUNG1-067\n",
      "No CT scan directory found for patient LUNG1-077\n",
      "No CT scan directory found for patient LUNG1-082\n",
      "No CT scan directory found for patient LUNG1-083\n",
      "No CT scan directory found for patient LUNG1-086\n",
      "No CT scan directory found for patient LUNG1-093\n",
      "No CT scan directory found for patient LUNG1-094\n",
      "No CT scan directory found for patient LUNG1-096\n",
      "No CT scan directory found for patient LUNG1-097\n",
      "No CT scan directory found for patient LUNG1-099\n",
      "No CT scan directory found for patient LUNG1-103\n",
      "No CT scan directory found for patient LUNG1-105\n",
      "No CT scan directory found for patient LUNG1-106\n",
      "No CT scan directory found for patient LUNG1-109\n",
      "No CT scan directory found for patient LUNG1-113\n",
      "No CT scan directory found for patient LUNG1-116\n",
      "No CT scan directory found for patient LUNG1-118\n",
      "No CT scan directory found for patient LUNG1-120\n",
      "No CT scan directory found for patient LUNG1-121\n",
      "No study directory found for patient LUNG1-128\n",
      "No CT scan directory found for patient LUNG1-129\n",
      "No CT scan directory found for patient LUNG1-130\n",
      "No CT scan directory found for patient LUNG1-134\n",
      "No study directory found for patient LUNG1-135\n",
      "No CT scan directory found for patient LUNG1-137\n",
      "No CT scan directory found for patient LUNG1-139\n",
      "No CT scan directory found for patient LUNG1-144\n",
      "No CT scan directory found for patient LUNG1-146\n",
      "No CT scan directory found for patient LUNG1-148\n",
      "No CT scan directory found for patient LUNG1-151\n",
      "No CT scan directory found for patient LUNG1-152\n",
      "No CT scan directory found for patient LUNG1-153\n",
      "No CT scan directory found for patient LUNG1-167\n",
      "No CT scan directory found for patient LUNG1-172\n",
      "No CT scan directory found for patient LUNG1-183\n",
      "No CT scan directory found for patient LUNG1-191\n",
      "No CT scan directory found for patient LUNG1-193\n",
      "No CT scan directory found for patient LUNG1-197\n",
      "No CT scan directory found for patient LUNG1-199\n",
      "No study directory found for patient LUNG1-200\n",
      "No study directory found for patient LUNG1-202\n",
      "No CT scan directory found for patient LUNG1-205\n",
      "No CT scan directory found for patient LUNG1-208\n",
      "No CT scan directory found for patient LUNG1-211\n",
      "No CT scan directory found for patient LUNG1-212\n",
      "No CT scan directory found for patient LUNG1-214\n",
      "No CT scan directory found for patient LUNG1-217\n",
      "No CT scan directory found for patient LUNG1-222\n",
      "No CT scan directory found for patient LUNG1-223\n",
      "No CT scan directory found for patient LUNG1-226\n",
      "No CT scan directory found for patient LUNG1-229\n",
      "No study directory found for patient LUNG1-230\n",
      "No CT scan directory found for patient LUNG1-234\n",
      "No CT scan directory found for patient LUNG1-235\n",
      "No CT scan directory found for patient LUNG1-237\n",
      "No study directory found for patient LUNG1-238\n",
      "No CT scan directory found for patient LUNG1-240\n",
      "No CT scan directory found for patient LUNG1-241\n",
      "No CT scan directory found for patient LUNG1-243\n",
      "No study directory found for patient LUNG1-250\n",
      "No study directory found for patient LUNG1-251\n",
      "No CT scan directory found for patient LUNG1-252\n",
      "No study directory found for patient LUNG1-254\n",
      "No CT scan directory found for patient LUNG1-256\n",
      "No CT scan directory found for patient LUNG1-264\n",
      "No study directory found for patient LUNG1-265\n",
      "No CT scan directory found for patient LUNG1-267\n",
      "No CT scan directory found for patient LUNG1-272\n",
      "No CT scan directory found for patient LUNG1-276\n",
      "No CT scan directory found for patient LUNG1-278\n",
      "No study directory found for patient LUNG1-279\n",
      "No CT scan directory found for patient LUNG1-281\n",
      "No CT scan directory found for patient LUNG1-285\n",
      "No CT scan directory found for patient LUNG1-286\n",
      "No CT scan directory found for patient LUNG1-298\n",
      "No CT scan directory found for patient LUNG1-299\n",
      "No study directory found for patient LUNG1-301\n",
      "No study directory found for patient LUNG1-302\n",
      "No study directory found for patient LUNG1-312\n",
      "No study directory found for patient LUNG1-314\n",
      "No study directory found for patient LUNG1-316\n",
      "No study directory found for patient LUNG1-319\n",
      "No CT scan directory found for patient LUNG1-321\n",
      "No study directory found for patient LUNG1-322\n",
      "No study directory found for patient LUNG1-324\n",
      "No study directory found for patient LUNG1-325\n",
      "No CT scan directory found for patient LUNG1-326\n",
      "No study directory found for patient LUNG1-327\n",
      "No study directory found for patient LUNG1-329\n",
      "No study directory found for patient LUNG1-330\n",
      "No study directory found for patient LUNG1-333\n",
      "No CT scan directory found for patient LUNG1-335\n",
      "No study directory found for patient LUNG1-336\n",
      "No study directory found for patient LUNG1-338\n",
      "No CT scan directory found for patient LUNG1-341\n",
      "No study directory found for patient LUNG1-344\n",
      "No study directory found for patient LUNG1-346\n",
      "No study directory found for patient LUNG1-348\n",
      "No CT scan directory found for patient LUNG1-349\n",
      "No study directory found for patient LUNG1-351\n",
      "No study directory found for patient LUNG1-352\n",
      "No study directory found for patient LUNG1-354\n",
      "No study directory found for patient LUNG1-355\n",
      "No study directory found for patient LUNG1-356\n",
      "No study directory found for patient LUNG1-357\n",
      "No study directory found for patient LUNG1-358\n",
      "No study directory found for patient LUNG1-359\n",
      "No study directory found for patient LUNG1-360\n",
      "No study directory found for patient LUNG1-361\n",
      "No study directory found for patient LUNG1-362\n",
      "No study directory found for patient LUNG1-363\n",
      "No study directory found for patient LUNG1-364\n",
      "No study directory found for patient LUNG1-365\n",
      "No study directory found for patient LUNG1-366\n",
      "No study directory found for patient LUNG1-367\n",
      "No study directory found for patient LUNG1-368\n",
      "No study directory found for patient LUNG1-369\n",
      "No study directory found for patient LUNG1-370\n",
      "No study directory found for patient LUNG1-371\n",
      "No study directory found for patient LUNG1-373\n",
      "No study directory found for patient LUNG1-374\n",
      "No study directory found for patient LUNG1-375\n",
      "No study directory found for patient LUNG1-376\n",
      "No study directory found for patient LUNG1-377\n",
      "No study directory found for patient LUNG1-378\n",
      "No study directory found for patient LUNG1-379\n",
      "No study directory found for patient LUNG1-380\n",
      "No study directory found for patient LUNG1-381\n",
      "No study directory found for patient LUNG1-382\n",
      "No study directory found for patient LUNG1-383\n",
      "No study directory found for patient LUNG1-384\n",
      "No study directory found for patient LUNG1-385\n",
      "No study directory found for patient LUNG1-386\n",
      "No study directory found for patient LUNG1-387\n",
      "No study directory found for patient LUNG1-388\n",
      "No study directory found for patient LUNG1-389\n",
      "No study directory found for patient LUNG1-390\n",
      "No study directory found for patient LUNG1-391\n",
      "No study directory found for patient LUNG1-392\n",
      "No study directory found for patient LUNG1-393\n",
      "No study directory found for patient LUNG1-394\n",
      "No study directory found for patient LUNG1-395\n",
      "No study directory found for patient LUNG1-396\n",
      "No study directory found for patient LUNG1-397\n",
      "No study directory found for patient LUNG1-398\n",
      "No study directory found for patient LUNG1-399\n",
      "No study directory found for patient LUNG1-400\n",
      "No study directory found for patient LUNG1-401\n",
      "No study directory found for patient LUNG1-402\n",
      "No study directory found for patient LUNG1-403\n",
      "No study directory found for patient LUNG1-404\n",
      "No study directory found for patient LUNG1-405\n",
      "No study directory found for patient LUNG1-406\n",
      "No study directory found for patient LUNG1-407\n",
      "No study directory found for patient LUNG1-408\n",
      "No study directory found for patient LUNG1-409\n",
      "No study directory found for patient LUNG1-410\n",
      "No study directory found for patient LUNG1-411\n",
      "No study directory found for patient LUNG1-412\n",
      "No study directory found for patient LUNG1-413\n",
      "No study directory found for patient LUNG1-414\n",
      "No study directory found for patient LUNG1-415\n",
      "No study directory found for patient LUNG1-416\n",
      "No study directory found for patient LUNG1-417\n",
      "No study directory found for patient LUNG1-418\n",
      "No study directory found for patient LUNG1-419\n",
      "No study directory found for patient LUNG1-420\n",
      "No study directory found for patient LUNG1-421\n",
      "No study directory found for patient LUNG1-422\n",
      "No CT scan directory found for patient LUNG1-029\n",
      "Created test dataset with 49 patients\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "print(\"Creating datasets with direct processing...\")\n",
    "train_dataset = DirectCTScanDataset(\n",
    "    base_dir=base_dir,\n",
    "    csv_path=csv_path,\n",
    "    patch_size=patch_size,\n",
    "    target_spacing=target_spacing,\n",
    "    target_shape=target_shape,\n",
    "    mode='train',\n",
    "    use_augmentation=use_augmentation\n",
    ")\n",
    "\n",
    "val_dataset = DirectCTScanDataset(\n",
    "    base_dir=base_dir,\n",
    "    csv_path=csv_path,\n",
    "    patch_size=patch_size,\n",
    "    target_spacing=target_spacing,\n",
    "    target_shape=target_shape,\n",
    "    mode='val',\n",
    "    use_augmentation=False\n",
    ")\n",
    "\n",
    "test_dataset = DirectCTScanDataset(\n",
    "    base_dir=base_dir,\n",
    "    csv_path=csv_path,\n",
    "    patch_size=patch_size,\n",
    "    target_spacing=target_spacing,\n",
    "    target_shape=target_shape,\n",
    "    mode='test',\n",
    "    use_augmentation=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "# Get sample weights for weighted random sampling\n",
    "sample_weights = train_dataset.get_sample_weights()\n",
    "sampler = WeightedRandomSampler(\n",
    "    weights=sample_weights,\n",
    "    num_samples=len(sample_weights),\n",
    "    replacement=True\n",
    ")\n",
    "\n",
    "# Use WeightedRandomSampler for training loader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    sampler=sampler,  # Use sampler instead of shuffle\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train the DenseNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating densenet121 model...\n"
     ]
    }
   ],
   "source": [
    "# Create model based on specified type\n",
    "print(f\"Creating {model_type} model...\")\n",
    "if model_type == \"densenet121\":\n",
    "    model = DenseNet121_3D(num_classes=4)\n",
    "elif model_type == \"densenet169\":\n",
    "    model = DenseNet169_3D(num_classes=4)\n",
    "elif model_type == \"densenet201\":\n",
    "    model = DenseNet201_3D(num_classes=4)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function with class weights and focal loss\n",
    "# Use combined loss (weighted cross-entropy + focal loss)\n",
    "criterion = CombinedLoss(\n",
    "    weight=train_dataset.class_weights.to(device),\n",
    "    gamma=2.0,  # Focal loss gamma parameter\n",
    "    alpha=0.5   # Weight between CE and focal loss\n",
    ")\n",
    "\n",
    "# Define optimizer with gradient clipping\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "# Define learning rate scheduler\n",
    "if scheduler_type == \"plateau\":\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "elif scheduler_type == \"cosine\":\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=1e-6)\n",
    "else:\n",
    "    raise ValueError(f\"Unknown scheduler type: {scheduler_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found best model checkpoint: densenet121_checkpoints_balanced\\best_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Create a new checkpoint directory for the modified model\n",
    "checkpoint_dir = f\"{model_type}_checkpoints_balanced\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "    print(f\"Created checkpoint directory: {checkpoint_dir}\")\n",
    "\n",
    "# Check if there's a checkpoint to resume from\n",
    "resume_from = None\n",
    "best_model_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "if os.path.exists(best_model_path):\n",
    "    resume_from = best_model_path\n",
    "    print(f\"Found best model checkpoint: {resume_from}\")\n",
    "    \n",
    "# Optionally, you can try to load weights from the previous model\n",
    "# This will use our new partial loading logic in train_model\n",
    "if not os.path.exists(best_model_path):\n",
    "    old_checkpoint_dir = f\"{model_type}_checkpoints\"\n",
    "    old_best_model_path = os.path.join(old_checkpoint_dir, \"best_model.pth\")\n",
    "    if os.path.exists(old_best_model_path):\n",
    "        resume_from = old_best_model_path\n",
    "        print(f\"No checkpoint found in new directory. Will try to load compatible weights from: {resume_from}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Loading checkpoint from densenet121_checkpoints_balanced\\best_model.pth\n",
      "Resuming from epoch 4 with best validation loss: 0.8486\n",
      "Progressive unfreezing schedule: [4, 10, 17, 23]\n",
      "Unfreezing denseblock4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 [Train]:   0%|          | 0/22 [00:00<?, ?it/s]d:\\ESPRIT\\4DS\\pi\\PulmoScan\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epoch 5/30 [Train]: 100%|██████████| 22/22 [25:45<00:00, 70.27s/it, loss=1.48, acc=0.294]   \n",
      "Epoch 5/30 [Val]: 100%|██████████| 4/4 [03:56<00:00, 59.09s/it, loss=0.517, acc=0.08]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 - Train Loss: 0.4759, Train Acc: 0.2941, Val Loss: 0.8686, Val Acc: 0.0800, LR: 0.000496\n",
      "No improvement for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 [Train]: 100%|██████████| 22/22 [23:03<00:00, 62.87s/it, loss=0.262, acc=0.347]  \n",
      "Epoch 6/30 [Val]: 100%|██████████| 4/4 [03:44<00:00, 56.08s/it, loss=0.911, acc=0.04]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class-wise validation performance:\n",
      "Classes present in validation set: ['Stage I', 'Stage II', 'Stage III']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Stage I       0.00      0.00      0.00         7\n",
      "    Stage II       0.04      1.00      0.08         1\n",
      "   Stage III       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.04        25\n",
      "   macro avg       0.01      0.33      0.03        25\n",
      "weighted avg       0.00      0.04      0.00        25\n",
      "\n",
      "Epoch 6/30 - Train Loss: 0.4035, Train Acc: 0.3471, Val Loss: 0.8498, Val Acc: 0.0400, LR: 0.000492\n",
      "Saved checkpoint to densenet121_checkpoints_balanced\\checkpoint_epoch_6.pth\n",
      "No improvement for 2 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 [Train]:   0%|          | 0/22 [00:00<?, ?it/s]d:\\ESPRIT\\4DS\\pi\\PulmoScan\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epoch 7/30 [Train]: 100%|██████████| 22/22 [24:34<00:00, 67.04s/it, loss=1.36, acc=0.341]  \n",
      "Epoch 7/30 [Val]: 100%|██████████| 4/4 [03:36<00:00, 54.14s/it, loss=0.749, acc=0.04]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 - Train Loss: 0.4725, Train Acc: 0.3412, Val Loss: 0.9145, Val Acc: 0.0400, LR: 0.000488\n",
      "No improvement for 3 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 [Train]: 100%|██████████| 22/22 [25:58<00:00, 70.85s/it, loss=0.84, acc=0.3]     \n",
      "Epoch 8/30 [Val]: 100%|██████████| 4/4 [03:43<00:00, 55.99s/it, loss=0.698, acc=0.04]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 - Train Loss: 0.4518, Train Acc: 0.3000, Val Loss: 0.7488, Val Acc: 0.0400, LR: 0.000482\n",
      "Saved checkpoint to densenet121_checkpoints_balanced\\checkpoint_epoch_8.pth\n",
      "Validation loss improved to 0.7488\n",
      "Saved best model to densenet121_checkpoints_balanced\\best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 [Train]: 100%|██████████| 22/22 [24:02<00:00, 65.56s/it, loss=1.22, acc=0.4]     \n",
      "Epoch 9/30 [Val]: 100%|██████████| 4/4 [03:36<00:00, 54.14s/it, loss=0.96, acc=0.04]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 - Train Loss: 0.3472, Train Acc: 0.4000, Val Loss: 0.9198, Val Acc: 0.0400, LR: 0.000476\n",
      "No improvement for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 [Train]: 100%|██████████| 22/22 [22:08<00:00, 60.39s/it, loss=1.21, acc=0.371] \n",
      "Epoch 10/30 [Val]: 100%|██████████| 4/4 [03:36<00:00, 54.22s/it, loss=0.679, acc=0.04]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 - Train Loss: 0.4248, Train Acc: 0.3706, Val Loss: 0.9028, Val Acc: 0.0400, LR: 0.000469\n",
      "Saved checkpoint to densenet121_checkpoints_balanced\\checkpoint_epoch_10.pth\n",
      "No improvement for 2 epochs\n",
      "Unfreezing denseblock3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 [Train]: 100%|██████████| 22/22 [23:12<00:00, 63.30s/it, loss=1.14, acc=0.318]   \n",
      "Epoch 11/30 [Val]: 100%|██████████| 4/4 [03:38<00:00, 54.67s/it, loss=0.628, acc=0.04]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class-wise validation performance:\n",
      "Classes present in validation set: ['Stage I', 'Stage II', 'Stage III']\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Stage I       0.00      0.00      0.00         7\n",
      "    Stage II       0.04      1.00      0.08         1\n",
      "   Stage III       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.04        25\n",
      "   macro avg       0.01      0.33      0.03        25\n",
      "weighted avg       0.00      0.04      0.00        25\n",
      "\n",
      "Epoch 11/30 - Train Loss: 0.4452, Train Acc: 0.3176, Val Loss: 0.7333, Val Acc: 0.0400, LR: 0.000461\n",
      "Validation loss improved to 0.7333\n",
      "Saved best model to densenet121_checkpoints_balanced\\best_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 [Train]:   0%|          | 0/22 [00:00<?, ?it/s]d:\\ESPRIT\\4DS\\pi\\PulmoScan\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Epoch 12/30 [Train]: 100%|██████████| 22/22 [22:13<00:00, 60.63s/it, loss=0.317, acc=0.294]  \n",
      "Epoch 12/30 [Val]: 100%|██████████| 4/4 [03:45<00:00, 56.27s/it, loss=0.475, acc=0.12]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 - Train Loss: 0.4917, Train Acc: 0.2941, Val Loss: 0.7479, Val Acc: 0.1200, LR: 0.000452\n",
      "Saved checkpoint to densenet121_checkpoints_balanced\\checkpoint_epoch_12.pth\n",
      "No improvement for 1 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 [Train]:  18%|█▊        | 4/22 [08:27<38:01, 126.76s/it, loss=0.326, acc=0.375]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting training...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model, history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Save checkpoint every 2 epochs\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresume_from\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogressive_unfreezing\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogressive_unfreezing\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ESPRIT\\4DS\\pi\\PulmoScan\\cancer_stage\\train_3d_densenet.py:155\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, num_epochs, patience, checkpoint_dir, save_freq, resume_from, progressive_unfreezing)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# Use tqdm for progress bar\u001b[39;00m\n\u001b[32m    154\u001b[39m train_pbar = tqdm(train_loader, desc=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m [Train]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_pbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Zero the parameter gradients\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ESPRIT\\4DS\\pi\\PulmoScan\\venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ESPRIT\\4DS\\pi\\PulmoScan\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ESPRIT\\4DS\\pi\\PulmoScan\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1491\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1488\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1490\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1491\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1492\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1494\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ESPRIT\\4DS\\pi\\PulmoScan\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1453\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1449\u001b[39m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[32m   1450\u001b[39m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[32m   1451\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1452\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1453\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1454\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1455\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ESPRIT\\4DS\\pi\\PulmoScan\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1271\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout=_utils.MP_STATUS_CHECK_INTERVAL):\n\u001b[32m   1272\u001b[39m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[32m   1273\u001b[39m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1281\u001b[39m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[32m   1282\u001b[39m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[32m   1283\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1284\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1285\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1287\u001b[39m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[32m   1288\u001b[39m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[32m   1289\u001b[39m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\queues.py:113\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[32m    112\u001b[39m     timeout = deadline - time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    114\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._poll():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\connection.py:256\u001b[39m, in \u001b[36m_ConnectionBase.poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    254\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    255\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\connection.py:329\u001b[39m, in \u001b[36mPipeConnection._poll\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m    327\u001b[39m             _winapi.PeekNamedPipe(\u001b[38;5;28mself\u001b[39m._handle)[\u001b[32m0\u001b[39m] != \u001b[32m0\u001b[39m):\n\u001b[32m    328\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\connection.py:878\u001b[39m, in \u001b[36mwait\u001b[39m\u001b[34m(object_list, timeout)\u001b[39m\n\u001b[32m    875\u001b[39m                 ready_objects.add(o)\n\u001b[32m    876\u001b[39m                 timeout = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m     ready_handles = \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    880\u001b[39m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[32m    881\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\multiprocessing\\connection.py:810\u001b[39m, in \u001b[36m_exhaustive_wait\u001b[39m\u001b[34m(handles, timeout)\u001b[39m\n\u001b[32m    808\u001b[39m ready = []\n\u001b[32m    809\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[32m--> \u001b[39m\u001b[32m810\u001b[39m     res = _winapi.WaitForMultipleObjects(L, \u001b[38;5;28;01mFalse\u001b[39;00m, timeout)\n\u001b[32m    811\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res == WAIT_TIMEOUT:\n\u001b[32m    812\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "print(\"Starting training...\")\n",
    "model, history = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    num_epochs=num_epochs,\n",
    "    patience=patience,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    save_freq=2,  # Save checkpoint every 2 epochs\n",
    "    resume_from=resume_from,\n",
    "    progressive_unfreezing=progressive_unfreezing\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 'densenet121_3d_cancer_stage.pth'\n"
     ]
    }
   ],
   "source": [
    "# Save trained model\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to '{model_save_path}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Plot training history\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m plot_training_history(\u001b[43mhistory\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 7/7 [12:31<00:00, 107.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.9165, Test Accuracy: 0.0408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_loss, test_acc, all_preds, all_labels = evaluate_model(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "class_names = ['Stage I', 'Stage II', 'Stage III', 'Stage IV']\n",
    "plot_confusion_matrix(all_labels, all_preds, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison with ResNet\n",
    "\n",
    "After training both the DenseNet and ResNet models, we can compare their performance using ROC curves and other metrics. This helps us understand which model is better suited for cancer stage classification, especially with imbalanced data.\n",
    "\n",
    "To run the comparison, use the `model_comparison.ipynb` notebook, which includes:\n",
    "- ROC curves for each class and model\n",
    "- Precision-recall curves\n",
    "- AUC and average precision scores\n",
    "- Confusion matrices\n",
    "\n",
    "This comparison is particularly important for imbalanced datasets like ours, where some cancer stages have fewer samples than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Run the model comparison notebook (uncomment to run)\n",
    "!jupyter notebook model_comparison.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Use a Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a trained model\n",
    "def load_trained_model(model_path, model_type=\"densenet121\", device=\"cuda\"):\n",
    "    # Create model based on specified type\n",
    "    if model_type == \"densenet121\":\n",
    "        model = DenseNet121_3D(num_classes=4)\n",
    "    elif model_type == \"densenet169\":\n",
    "        model = DenseNet169_3D(num_classes=4)\n",
    "    elif model_type == \"densenet201\":\n",
    "        model = DenseNet201_3D(num_classes=4)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    # Load model weights\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Example usage:\n",
    "# trained_model = load_trained_model(\"densenet121_3d_cancer_stage.pth\", model_type=\"densenet121\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict cancer stage for a single CT scan\n",
    "def predict_cancer_stage(model, ct_scan_path, seg_mask_path, device=\"cuda\"):\n",
    "    from ct_preprocessing import preprocess_ct_scan, load_dicom_series_safely\n",
    "    \n",
    "    # Load and preprocess CT scan\n",
    "    ct_volume, _ = load_dicom_series_safely(ct_scan_path)\n",
    "    preprocessed_volume = preprocess_ct_scan(ct_volume, target_spacing=(1.0, 1.0, 1.0), target_shape=(128, 256, 256))\n",
    "    \n",
    "    # Convert to tensor and add batch and channel dimensions\n",
    "    volume_tensor = torch.from_numpy(preprocessed_volume).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Make prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = model(volume_tensor)\n",
    "        probabilities = torch.softmax(outputs, dim=1)\n",
    "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    \n",
    "    # Map class index to stage name\n",
    "    stage_names = ['Stage I', 'Stage II', 'Stage III', 'Stage IV']\n",
    "    predicted_stage = stage_names[predicted_class]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    probs = probabilities.cpu().numpy()[0]\n",
    "    \n",
    "    return predicted_stage, probs\n",
    "\n",
    "# Example usage:\n",
    "# patient_id = \"LUNG1-001\"\n",
    "# ct_path = f\"E:/cancer stage/NSCLC-Radiomics/{patient_id}/...\"\n",
    "# seg_path = f\"E:/cancer stage/NSCLC-Radiomics/{patient_id}/...\"\n",
    "# predicted_stage, probabilities = predict_cancer_stage(trained_model, ct_path, seg_path, device=device)\n",
    "# print(f\"Predicted cancer stage: {predicted_stage}\")\n",
    "# for stage, prob in zip(['Stage I', 'Stage II', 'Stage III', 'Stage IV'], probabilities):\n",
    "#     print(f\"{stage}: {prob:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
